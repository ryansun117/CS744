Part3 Task3
  
part3_3.py contains all code for Part3 Task3 of the assignment

To run part3_3.py, execute run.sh in this directory

Note that we assume Hadoop and Spark exist in /mnt/data/hadoop-3.3.4/ and /mnt/data/spark-3.3.0-bin-hadoop3/, part3_3.py exists in /mnt/data/part3_3/part3_3.py, and enwiki-pages-articles exist in hdfs://10.10.1.1:9000/data-part3/enwiki-pages-articles

It might be possible that when running the code and writing the output file to HDFS, you will encounter permission error. In this case, change the permission of HDFS by executing a command similar to /mnt/data/hadoop-3.3.4/bin/hdfs dfs -chmod -R 777 /

List files in HDFS with /mnt/data/hadoop-3.3.4/bin/hdfs dfs -ls /
